{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Effect:\n",
    "    all_effects = []\n",
    "    bath = pd.read_pickle('data/bath_pickle.pkl')\n",
    "\n",
    "    def __init__(self, description: str, lower_threshold: float, upper_threshold: float, cost_equation: str, units: str):\n",
    "        self.description = description\n",
    "        self.lower_threshold = lower_threshold\n",
    "        self.upper_threshold = upper_threshold\n",
    "        self.cost_equation = cost_equation\n",
    "        self.units = units\n",
    "        Effect.all_effects.append(self)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.description\n",
    "\n",
    "    def cost_function(self, elevation_m: float) -> float:\n",
    "        if self.cost_equation == '':\n",
    "            return 0\n",
    "        MAX_SURFACE_AREA = 5574.65\n",
    "        exposed_km2 = MAX_SURFACE_AREA - Effect.bath.at[round(elevation_m,2), 'Surface Area']\n",
    "        return eval(self.cost_equation.split('=')[1])\n",
    "    \n",
    "    def filled_description(self, elevation: float) -> str:\n",
    "        cost = self.format_cost_to_print(self.cost_function(elevation))\n",
    "        return self.description.format(cost=cost)\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_cost_to_print(cost: float) -> str:\n",
    "        if cost > 1000000000:\n",
    "            word = 'billion'\n",
    "            cost /= 1000000000\n",
    "            return f'${cost:.1f} {word}'\n",
    "        elif cost > 1000000:\n",
    "            word = 'million'\n",
    "            cost /= 1000000            \n",
    "            return f'${cost:.1f} {word}'\n",
    "        elif cost > 1000:\n",
    "            return f'${round(cost/1000)},000'\n",
    "        else:\n",
    "            return f'${cost:.0f}'\n",
    "    \n",
    "    @classmethod\n",
    "    def instantiate_from_csv(cls, path:str):\n",
    "        with open(path, 'r') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            effects = list(reader)\n",
    "        for effect in effects:\n",
    "            if type(effect.get('effect_description')) is  None:\n",
    "                print('nonetype')\n",
    "            Effect(\n",
    "                description = effect.get('effect_description'),\n",
    "                lower_threshold = float(effect.get('lower_m')),\n",
    "                upper_threshold = float(effect.get('upper_m')),\n",
    "                cost_equation = effect.get('cost_equation'),\n",
    "                units = effect.get('units')\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority of wetlands are adversely affected.\n"
     ]
    }
   ],
   "source": [
    "Effect.instantiate_from_csv('data/elevation_effects.csv')\n",
    "\n",
    "print(Effect.all_effects[2].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agriculture_consumption',\n",
       " 'avg_elevation',\n",
       " 'evap_km3_per_km2',\n",
       " 'groundwater',\n",
       " 'impounded_wetland_consumption',\n",
       " 'mineral_consumption',\n",
       " 'municipal_consumption',\n",
       " 'percip_km3_per_km2',\n",
       " 'reservoir_consumption',\n",
       " 'streamflow_after_consumption',\n",
       " 'streamflow_before_consumption',\n",
       " 'total_consumptive_use',\n",
       " 'utah_population_millions',\n",
       " 'water_imports']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DataSchema:\n",
    "    streamflow_after_consumption = 'streamflow_after_consumption'\n",
    "    groundwater = 'groundwater'\n",
    "    evap_km3_per_km2 = 'evap_km3_per_km2'\n",
    "    percip_km3_per_km2 = 'percip_km3_per_km2'\n",
    "    total_consumptive_use = 'total_consumptive_use'\n",
    "    streamflow_before_consumption = 'streamflow_before_consumption'\n",
    "    agriculture_consumption = 'agriculture_consumption'\n",
    "    municipal_consumption = 'municipal_consumption'\n",
    "    mineral_consumption =  'mineral_consumption'\n",
    "    impounded_wetland_consumption = 'impounded_wetland_consumption'\n",
    "    reservoir_consumption =  'reservoir_consumption'\n",
    "    water_imports = 'water_imports'\n",
    "    utah_population_millions = 'utah_population_millions'\n",
    "    avg_elevation = 'avg_elevation'\n",
    "[x for x in dir(DataSchema) if not x.startswith('__')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {'try': 2}\n",
    "'2' in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateLineGraph(prediction: pd.DataFrame, lr_average_elevaton: float, df_lake: pd.DataFrame, units: str, rolling=5) -> px.scatter:\n",
    "\n",
    "    MEAN_ELEVATION_BEFORE_1847 = 1282.3\n",
    "    # trendline_y_points = [1281.7,1278.9]\n",
    "    METERS_TO_FEET = 3.28084\n",
    "\n",
    "    historic_avg_elevation = round(df_lake[DataSchema.avg_elevation].mean(),2)\n",
    "    combined = pd.concat([df_lake,prediction],ignore_index=True)\n",
    "\n",
    "    temp = pd.concat([combined.iloc[len(df_lake)-rolling:len(df_lake)][DataSchema.avg_elevation],combined.iloc[len(df_lake):]['Elevation Prediction']])\n",
    "    combined['Elevation Prediction'] = temp\n",
    "\n",
    "    if units == 'imperial':\n",
    "        elevation_unit = 'ft'\n",
    "        combined['Elevation Prediction'] *= METERS_TO_FEET\n",
    "        lr_average_elevaton *= METERS_TO_FEET\n",
    "        combined[DataSchema.avg_elevation] *= METERS_TO_FEET\n",
    "        MEAN_ELEVATION_BEFORE_1847 *= METERS_TO_FEET\n",
    "        historic_avg_elevation *= METERS_TO_FEET\n",
    "        # trendline_y_points = [y * METERS_TO_FEET for y in trendline_y_points]\n",
    "    else:\n",
    "        elevation_unit = 'm'\n",
    "\n",
    "    colors = ['blue','red']\n",
    "\n",
    "    combined['datetime'] = pd.to_datetime(combined['datetime'])\n",
    "\n",
    "    fig = px.scatter(combined, y=[DataSchema.avg_elevation,'Elevation Prediction'],\n",
    "                        x='datetime', trendline='rolling',\n",
    "                        trendline_options=dict(window=rolling),\n",
    "                        color_discrete_sequence=colors,\n",
    "                        labels = {\n",
    "                            'value':f'Lake Elevation ({elevation_unit})',\n",
    "                            'datetime':'Year'\n",
    "                        },\n",
    "                    )\n",
    "\n",
    "    start_date = \"1870-01-01\"\n",
    "    end_date = combined.at[len(combined)-1, \"datetime\"]\n",
    "    fig.update_xaxes(type='date', range=[start_date, end_date])\n",
    "\n",
    "    #only show trendlines\n",
    "    fig.data = [t for t in fig.data if t.mode == 'lines']\n",
    "\n",
    "    lr_pos = 'bottom left'\n",
    "    human_pos = 'top left'\n",
    "\n",
    "    fig.add_hline(y=MEAN_ELEVATION_BEFORE_1847, line_dash='dot',\n",
    "                    annotation_text = f'Average Natural Level, {MEAN_ELEVATION_BEFORE_1847}{elevation_unit}',\n",
    "                    annotation_position = 'top left',\n",
    "                    annotation_font_size = 10,\n",
    "                    annotation_font_color = 'black',\n",
    "                    )\n",
    "\n",
    "    fig.add_hline(y=historic_avg_elevation, line_dash='dot',\n",
    "                annotation_text = f'Average Since 1847, {historic_avg_elevation}{elevation_unit}',\n",
    "                annotation_position = human_pos,\n",
    "                annotation_font_size = 10,\n",
    "                annotation_font_color = colors[0],\n",
    "                line_color = colors[0],\n",
    "                )\n",
    "\n",
    "    fig.add_hline(y=lr_average_elevaton, \n",
    "                    line_dash='dot',\n",
    "                    annotation_text = f'Long-term Policy Average, {lr_average_elevaton}{elevation_unit}',\n",
    "                    annotation_position = lr_pos,\n",
    "                    annotation_font_size = 10,\n",
    "                    annotation_font_color = colors[1],\n",
    "                    line_color = colors[1],\n",
    "            )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b55733d1840a0be1758c73097f27f9b2fa130991d8714818b6a7a4fc9ef5f47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
